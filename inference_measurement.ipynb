{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    # Fantasy\n",
    "    \"A majestic griffin soaring through a vibrant nebula, its feathers shimmering with starlight.\",\n",
    "    \"A hidden dwarven city carved into a colossal mountain, bathed in the warm glow of lava.\",\n",
    "    \"A fierce battle between a band of orcs and a group of valiant elves in an enchanted forest.\",\n",
    "    \"A lone mermaid swimming through a bioluminescent coral reef, surrounded by colorful fish.\",\n",
    "    \"A towering wizard casting a powerful spell, runes swirling around them in a mystical chamber.\",\n",
    "\n",
    "    # Sci-Fi\n",
    "    \"A sleek spaceship exploring a ringed gas giant, with a breathtaking view of the aurora borealis.\",\n",
    "    \"A team of astronauts on a desolate alien planet, discovering a cryptic message carved into a rocky surface.\",\n",
    "    \"A bustling cyberpunk marketplace filled with neon signs, holograms, and robotic vendors.\",\n",
    "    \"A lone cyborg warrior standing amidst the ruins of a futuristic city, bathed in moonlight.\",\n",
    "    \"A breathtaking view of a space colony orbiting a lush green planet, with a shimmering space station in the foreground.\",\n",
    "\n",
    "    # Nature\n",
    "    \"A majestic waterfall cascading down a mossy cliff face, surrounded by lush green ferns and vibrant wildflowers.\",\n",
    "    \"A majestic lion stalking its prey through a golden savanna at sunset, with a vibrant orange sky.\",\n",
    "    \"A lone wolf howling at the full moon, silhouetted against a snow-capped mountain range.\",\n",
    "    \"A vibrant coral reef teeming with colorful fish, sunlight filtering through the crystal-clear water.\",\n",
    "    \"A breathtaking panorama of a misty mountain valley with a winding river and a charming wooden bridge.\",\n",
    "\n",
    "    # Mythology\n",
    "    \"A fierce battle between Zeus and Poseidon, wielding lightning and a trident amidst swirling clouds.\",\n",
    "    \"A beautiful phoenix rising from the ashes, its wings spread wide and bathed in fiery light.\",\n",
    "    \"A wise centaur teaching a young human warrior the art of archery in a sun-dappled forest.\",\n",
    "    \"A mischievous group of satyrs dancing with playful nymphs in a moonlit forest, surrounded by glowing mushrooms.\",\n",
    "    \"A majestic griffin pulling the chariot of the Greek goddess Athena, soaring across a clear blue sky.\",\n",
    "\n",
    "    # History\n",
    "    \"A detailed portrait of a young Cleopatra adorned with gold jewelry, gazing confidently out at the viewer.\",\n",
    "    \"A bustling marketplace in medieval Europe, with merchants selling various goods and people dressed in period clothing.\",\n",
    "    \"A dramatic scene of the signing of the Declaration of Independence, with historical figures like John Adams and Benjamin Franklin.\",\n",
    "    \"A pharaoh's tomb filled with golden treasures and hieroglyphics, illuminated by flickering torches.\",\n",
    "    \"A fierce battle scene between Roman legionaries and barbarian warriors, with swords clashing and smoke filling the air.\",\n",
    "\n",
    "    # Portrait\n",
    "    \"A close-up portrait of an elderly Asian woman with kind eyes and a gentle smile, wrinkles etched onto her face.\",\n",
    "    \"A young African-American man with a vibrant afro hairstyle, wearing a stylish outfit and exuding confidence.\",\n",
    "    \"A woman with flowing red hair and freckles, wearing a flowing green dress and gazing wistfully into the distance.\",\n",
    "    \"A man with a long, braided beard and piercing blue eyes, wearing a Viking helmet and leather armor.\",\n",
    "    \"A child with bright green eyes and a mischievous grin, playfully peeking out from behind a colorful curtain.\",\n",
    "\n",
    "    # Surreal\n",
    "    \"A melting clock dripping down a cobblestone street in a dreamlike cityscape with impossible architecture.\",\n",
    "    \"A chessboard where the pieces are giant desserts like cupcakes and castles made of ice cream.\",\n",
    "    \"A woman with a book for a head, leaves turning its pages as she walks through a magical forest.\",\n",
    "    \"A staircase that spirals endlessly upwards into a swirling vortex of clouds at the top.\",\n",
    "    \"A room filled with doors leading to unexpected locations, like a bustling underwater market or a field of giant flowers.\",\n",
    "\n",
    "    # Horror\n",
    "    \"A dark and decaying mansion shrouded in mist, with a single glowing window revealing a shadowy figure.\",\n",
    "    \"A group of terrified teenagers running through a dark forest, chased by a monstrous creature with glowing eyes.\",\n",
    "    \"A close-up of a decaying zombie face, with rotting flesh and bloodshot eyes staring out.\",\n",
    "    \"A haunted graveyard at night, with tombstones casting long shadows and a ghostly figure floating through the air.\",\n",
    "    \"A creepy children's nursery with broken toys, rocking chairs swaying on their own, and an unsettling silence.\",\n",
    "\n",
    "    # Food\n",
    "    \"A slice of a freshly baked chocolate cake with rich frosting and colorful sprinkles, drizzled with melted chocolate.\",\n",
    "    \"A steaming bowl of Japanese ramen with perfectly cooked noodles, meat slices, a soft-boiled egg, and a flavorful broth.\",\n",
    "    \"A juicy burger with melted cheese, crisp lettuce, and a perfectly toasted bun, served with golden french\",\n",
    "    \"A rustic wooden table overflowing with a colorful charcuterie board, featuring cured meats, cheeses, fresh grapes, and crusty bread.\",\n",
    "    \"A steaming cup of creamy latte art, with intricate designs like a swan or a heart floating on top.\",\n",
    "    \n",
    "    #Abstract Art\n",
    "    \"A vibrant composition of geometric shapes in contrasting colors, creating a sense of movement and dynamism.\",\n",
    "    \"A swirling mass of textured brushstrokes in calming earth tones, evoking a feeling of serenity and peace.\",\n",
    "    \"A canvas filled with splatters and drips of metallic paint, capturing the raw energy and chaos of the creative process.\",\n",
    "    \"A minimalist composition featuring a single line or dot against a vast expanse of white space, exploring the beauty of simplicity.\",\n",
    "    \"A gradient blend of vibrant colors, transitioning seamlessly from one hue to another, creating a sense of depth and mystery.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forms vote information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[i for i in range(50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_score(image_path, text):\n",
    "    # Load the pre-trained CLIP model and the image\n",
    "    model, preprocess = clip.load('ViT-B/32')\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Preprocess the image and tokenize the text\n",
    "    image_input = preprocess(image).unsqueeze(0)\n",
    "    text_input = clip.tokenize([text])\n",
    "    \n",
    "    # Move the inputs to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    image_input = image_input.to(device)\n",
    "    text_input = text_input.to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Generate embeddings for the image and text\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        text_features = model.encode_text(text_input)\n",
    "    \n",
    "    # Normalize the features\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    # Calculate the cosine similarity to get the CLIP score\n",
    "    clip_score = torch.matmul(image_features, text_features.T).item()\n",
    "    \n",
    "    return clip_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"prompts\":prompts})\n",
    "dpo_scores=[]\n",
    "for i in range(len(prompts)):\n",
    "    image_path = \"DPO_imgs\\img\"+str(i)+\".png\"\n",
    "    text = prompts[i]\n",
    "    dpo_scores.append(get_clip_score(image_path, text))\n",
    "df[\"clip_dpo\"]=dpo_scores\n",
    "\n",
    "rlhf_scores=[]\n",
    "for i in range(len(prompts)):\n",
    "    image_path = \"RLHF_imgs\\img\"+str(i)+\".png\"\n",
    "    text = prompts[i]\n",
    "    rlhf_scores.append(get_clip_score(image_path, text))\n",
    "df[\"clip_rlhf\"]=rlhf_scores\n",
    "\n",
    "df[\"dpo_better\"]=df[\"clip_dpo\"]>df[\"clip_rlhf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO was better :  74.0 %\n",
      "RLHF was better :  26.0 %\n"
     ]
    }
   ],
   "source": [
    "#According to CLIP dpo was better than RLHF 37/50 times.\n",
    "print(\"DPO was better : \",(df[df[\"dpo_better\"]==True].shape[0]/df.shape[0])*100, \"%\\nRLHF was better : \",(df[df[\"dpo_better\"]==False].shape[0]/df.shape[0])*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon trying with the cosine simliarity method instead of matmul of pytorch we found the same answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frechet Inception Distance (FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import shuffle\n",
    "from scipy.linalg import sqrtm\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(model, images1, images2):\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (50, 512, 512, 3) (50, 512, 512, 3) (50, 1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "images1=[]\n",
    "images2=[]\n",
    "images3=[]\n",
    "for i in range(0, len(prompts)):\n",
    "    images1.append(np.array(Image.open(\"DPO_imgs\\img\"+str(i)+\".png\")))\n",
    "    images2.append(np.array(Image.open(\"RLHF_imgs\\img\"+str(i)+\".png\")))\n",
    "    images3.append(np.array(Image.open(\"SDXL_imgs\\img\"+str(i)+\".png\")))\n",
    "images1=np.asarray(images1)\n",
    "images2=np.asarray(images2)\n",
    "images3=np.asarray(images3)\n",
    "images1 = images1.astype('float32')\n",
    "images2 = images2.astype('float32')\n",
    "images3 = images3.astype('float32')\n",
    "\n",
    "print('Loaded', images1.shape, images2.shape, images3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled (50, 299, 299, 3) (50, 299, 299, 3) (50, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "images1 = scale_images(images1, (299,299,3))\n",
    "images2 = scale_images(images2, (299,299,3))\n",
    "images3 = scale_images(images3, (299,299,3))\n",
    "print('Scaled', images1.shape, images2.shape,images3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 903ms/step\n",
      "2/2 [==============================] - 2s 869ms/step\n",
      "FID DPO vs SDXL: 215.046\n",
      "2/2 [==============================] - 2s 727ms/step\n",
      "2/2 [==============================] - 2s 737ms/step\n",
      "FID RLHF vs SDXL: 246.931\n"
     ]
    }
   ],
   "source": [
    "images1 = preprocess_input(images1)\n",
    "images2 = preprocess_input(images2)\n",
    "images3 = preprocess_input(images3)\n",
    "fid = calculate_fid(model, images1, images3)\n",
    "print('FID DPO vs SDXL: %.3f' % fid)\n",
    "fid = calculate_fid(model, images2, images3)\n",
    "print('FID RLHF vs SDXL: %.3f' % fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher score of FID with SDXL shows that the image distribution of RLHF is less comparable to sdxl than dpo, **meaning dpo is more like sdxl than rlhf**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Similarity Index Measure (SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel=1):\n",
    "    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)\n",
    "    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def ssim(img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):\n",
    "    L = val_range # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),\n",
    "    pad = window_size // 2\n",
    "    try:\n",
    "        _, channels, height, width = img1.size()\n",
    "    except:\n",
    "        channels, height, width = img1.size()\n",
    "    # if window is not provided, init one\n",
    "    if window is None: \n",
    "        real_size = min(window_size, height, width) # window should be atleast 11x11 \n",
    "        window = create_window(real_size, channel=channels).to(img1.device)\n",
    "    # calculating the mu parameter (locally) for both images using a gaussian filter \n",
    "    # calculates the luminosity params\n",
    "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2 \n",
    "    mu12 = mu1 * mu2\n",
    "    # now we calculate the sigma square parameter\n",
    "    # Sigma deals with the contrast component \n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
    "    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
    "    # Some constants for stability \n",
    "    C1 = (0.01 ) ** 2  # NOTE: Removed L from here (ref PT implementation)\n",
    "    C2 = (0.03 ) ** 2 \n",
    "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    contrast_metric = torch.mean(contrast_metric)\n",
    "    numerator1 = 2 * mu12 + C1  \n",
    "    numerator2 = 2 * sigma12 + C2\n",
    "    denominator1 = mu1_sq + mu2_sq + C1 \n",
    "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
    "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
    "    if size_average:\n",
    "        ret = ssim_score.mean() \n",
    "    else: \n",
    "        ret = ssim_score.mean(1).mean(1).mean(1)\n",
    "    if full:\n",
    "        return ret, contrast_metric\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images = lambda x: np.asarray(Image.open(x).resize((480, 640)))\n",
    "tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samth\\AppData\\Local\\Temp\\ipykernel_29280\\2749427999.py:2: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)\n"
     ]
    }
   ],
   "source": [
    "ssim_rlhf=[]\n",
    "ssim_dpo=[]\n",
    "for i in range(len(prompts)):\n",
    "    rlhf = load_images(\"RLHF_imgs/img\"+str(i)+\".png\")\n",
    "    dpo = load_images(\"DPO_imgs/img\"+str(i)+\".png\")\n",
    "    sdxl = load_images(\"SDXL_imgs/img\"+str(i)+\".png\")\n",
    "    _rlhf = tensorify(rlhf)\n",
    "    _dpo = tensorify(dpo)\n",
    "    _sdxl = tensorify(sdxl)\n",
    "    rlhf_sdxl = ssim(_rlhf, _sdxl, val_range=255)\n",
    "    dpo_sdxl = ssim(_dpo, _sdxl, val_range=255)\n",
    "    ssim_rlhf.append(float(rlhf_sdxl))\n",
    "    ssim_dpo.append(float(dpo_sdxl))\n",
    "\n",
    "df[\"SSIM_rlhf\"]=ssim_rlhf\n",
    "df[\"SSIM_dpo\"]=ssim_dpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPO was more structurally similar to  SDXL:  98.0 %\n",
      "RLHF was more structurally similar to SDXL :  2.0 %\n"
     ]
    }
   ],
   "source": [
    "df[\"dpo_better_ssim\"]=df[\"SSIM_dpo\"]>=df[\"SSIM_rlhf\"]\n",
    "print(\"DPO was more structurally similar to  SDXL: \",(df[df[\"dpo_better_ssim\"]==True].shape[0]/df.shape[0])*100, \"%\\nRLHF was more structurally similar to SDXL : \",(df[df[\"dpo_better_ssim\"]==False].shape[0]/df.shape[0])*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Report 1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A bustling cyberpunk marketplace filled with neon signs, holograms, and robotic vendors.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (418614619.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    1 prompt adherence\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 1 * prompt adherence\n",
    "# 2 * comparitive analysis with sdxl\n",
    "# 1 * prompt adherence from vote\n",
    "# 1 * favourability index from vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
