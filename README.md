# RLHFvsDPO
This repository aims to identify and define the differences between the fine tuning methods RLHF (Real Life Human Feedback) and DPO (Direct Preference Optimization) for GIMs (Generative Image Models)  for specific niche scenarios.
